The baseline accuracy of the spellchecker on the initially given corpus and test data was 78.38%.

There were many words in the sample dataset with edit distances of 2 to their corrected versions, so my first improvement was, as in Peter Norvig's article, consider words with an edit distance of 2 to the original word. This improved the accuracy of the program from the baseline of 78.38% to 80.73%. This wasn't a good enough improvement, especially considering the change dramatically slowed the program down.

The thing limiting the spellchecker's accuracy was that some words in the test data did not occur in the original corpus at all. The next idea I had about an improvement was trying to derive new words from the existing ones in the corpus (e.g plurals) but this was completely against the purpose of a spellchecker since we can't be sure about correctness of the spelling of the new words we just derived, so that improvement was out of the question. So I literally expanded the corpus, by adding some books from Project Gutenberg and a word list of 100.000 words. The size of the corpus grew from 6.5 megabytes to 10.9 megabytes. The accuracy of the spellchecker with the new corpus (and the previous improvement as well) is 87.23%
